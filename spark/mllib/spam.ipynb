{"nbformat_minor": 2, "cells": [{"execution_count": 4, "cell_type": "code", "source": "# Load ML libraries\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.feature import HashingTF\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS\n\n# Create RDDs of Spam and Normal text\nspam = sc.textFile(\"spam.txt\")\nnormal = sc.textFile(\"normal.txt\")\n\n# Create a HashingTF instance to map email text to vectors of 10,000 features.\ntf = HashingTF(numFeatures = 10000)\n\n# Each email is split into words, and each word is mapped to one feature.\nspamFeatures = spam.map(lambda email: tf.transform(email.split(\" \")))\nnormalFeatures = normal.map(lambda email: tf.transform(email.split(\" \")))\n\n# Create LabeledPoint datasets for positive (spam) and negative (normal) examples.\npositiveExamples = spamFeatures.map(lambda features: LabeledPoint(1, features))\nnegativeExamples = normalFeatures.map(lambda features: LabeledPoint(0, features))\ntrainingData = positiveExamples.union(negativeExamples)\ntrainingData.cache() # Cache since Logistic Regression is an iterative algorithm.\n\n# Run Logistic Regression using the LBFGS algorithm.\nmodel = LogisticRegressionWithLBFGS.train(trainingData)\n\n# Test on a positive example (spam) and a negative one (normal). We first apply\n# the same HashingTF feature transformation to get vectors, then apply the model.\nposTest = tf.transform(\"I recently inherited wealth, send me money ...\".split(\" \"))\nnegTest = tf.transform(\"Hi Dad, I started studying Spark the other ...\".split(\" \"))\nprint (\"Prediction for positive test example: %g\" % model.predict(posTest))\nprint (\"Prediction for negative test example: %g\" % model.predict(negTest))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Prediction for positive test example: 0\nPrediction for negative test example: 0"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}