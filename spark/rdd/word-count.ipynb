{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Python Regular Expression module\n",
    "import re\n",
    "# Define a function to remove any special characters\n",
    "def removePunctuation(text):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-z0-9\\s]','',text.lower().strip())\n",
    "\n",
    "# Load the two-cities corpus from the Azure storage blob (/user/livy/)\n",
    "corpus = sc.textFile(\"two-cities.txt\")\n",
    "# Word count\n",
    "counts = corpus.flatMap(lambda line: removePunctuation(line).split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b) \\\n",
    "             .filter(lambda x: x[1]>=10)\n",
    "output = counts.collect()\n",
    "# Print word counts\n",
    "for (word, count) in output:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
