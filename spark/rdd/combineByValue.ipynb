{"nbformat_minor": 2, "cells": [{"execution_count": 7, "cell_type": "code", "source": "data = sc.parallelize([(0, 2.), (0, 4.), (1, 0.), (1, 10.), (1, 20.), (1, 30)])\n\nsumCount = data.combineByKey(lambda value: (value, 1),\n                             lambda x, value: (x[0] + value, x[1] + 1),\n                             lambda x, y: (x[0] + y[0], x[1] + y[1]))\n\n#averageByKey = sumCount.map(lambda label, value_sum: (label, value_sum[0] / value_sum[1]))\n\nsumCount.collect()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(0, (6.0, 2)), (1, (60.0, 4))]"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# Key of 1\n# Partition 1\n(1, 0) (1, 10) (1, 30)\n\n# Partition 2\n(1, 20)\n\n# Create valeu, 1 pairs #lambda value: (value, 1),\n(0, 1)\n#partition 2\n(20, 1)\n\n(10, 2) # par1 (lambda x, value: x[0] + value, x[1]+1)\n        #      (lambda (0,1), 10: 0 + 10, 1 + 1)\n        #  => (10, 2)\n        (10, 2)\n        # par1 (lambda x, value: x[0] + value, x[1]+1)\n        #      (lambda (10,2), 30: 10 + 30, 2 + 1)\n        #  => (40, 3)     \n        \n(20, 1) # par2\n# lambda x, y: (x[0] + y[0], x[1] + y[1])\n(1,(60, 4))", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}