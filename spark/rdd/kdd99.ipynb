{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "# Create an RDD from the KDD99 10% dataset\ndata_file = \"./kddcup.data_10_percent.gz\"\nraw_data = sc.textFile(data_file)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1499674741924_0003</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-kbtu.3bs2jaxxb12u1ll00rolucu4sg.ax.internal.cloudapp.net:8088/proxy/application_1499674741924_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.11:30060/node/containerlogs/container_1499674741924_0003_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n"}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "# Count the number of lines in the raw dataset\nraw_data.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "494021"}], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "# Print first few entries\nraw_data.take(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "['0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.', '0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,19,19,1.00,0.00,0.05,0.00,0.00,0.00,0.00,0.00,normal.', '0,tcp,http,SF,235,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,29,29,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.', '0,tcp,http,SF,219,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,6,0.00,0.00,0.00,0.00,1.00,0.00,0.00,39,39,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.', '0,tcp,http,SF,217,2032,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,6,0.00,0.00,0.00,0.00,1.00,0.00,0.00,49,49,1.00,0.00,0.02,0.00,0.00,0.00,0.00,0.00,normal.']"}], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": "# Filter `normal` data\nnormal_raw_data = raw_data.filter(lambda x: 'normal.' in x)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "# Count the normal data and measure time\nfrom time import time\nt0 = time()\nnormal_count = normal_raw_data.count()\ntt = time() - t0\nprint (\"There are {} 'normal' interactions\".format(normal_count))\nprint (\"Count completed in {} seconds\".format(round(tt,3)))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "There are 97278 'normal' interactions\nCount completed in 1.331 seconds"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "# Sample data\nraw_data_sample = raw_data.sample(False, 0.1, 1234)\nsample_size = raw_data_sample.count()\ntotal_size = raw_data.count()\nprint (\"Sample size is {} of {}\".format(sample_size, total_size))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Sample size is 49493 of 494021"}], "metadata": {"collapsed": false}}, {"execution_count": 12, "cell_type": "code", "source": "# Measuring the normal interaction in the sample dataset\nfrom time import time\n\n# transformations to get normal data\nraw_data_sample_items = raw_data_sample.map(lambda x: x.split(\",\"))\nsample_normal_tags = raw_data_sample_items.filter(lambda x: \"normal.\" in x)\n\n# actions + time\nt0 = time()\nsample_normal_tags_count = sample_normal_tags.count()\ntt = time() - t0\n\nsample_normal_ratio = sample_normal_tags_count / float(sample_size)\nprint (\"The ratio of 'normal' interactions is {}\".format(round(sample_normal_ratio,3)))\nprint (\"Count done in {} seconds\".format(round(tt,3)))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "The ratio of 'normal' interactions is 0.195\nCount done in 1.709 seconds"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "# Measuring the normal interaction in the entire dataset\nraw_data_items = raw_data.map(lambda x: x.split(\",\"))\nnormal_tags = raw_data_items.filter(lambda x: \"normal.\" in x)\n\n# actions + time\nt0 = time()\nnormal_tags_count = normal_tags.count()\ntt = time() - t0\n\nnormal_ratio = normal_tags_count / float(total_size)\nprint (\"The ratio of 'normal' interactions is {}\".format(round(sample_normal_ratio,3)))\nprint (\"Count done in {} seconds\".format(round(tt,3)))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "The ratio of 'normal' interactions is 0.195\nCount done in 2.726 seconds"}], "metadata": {"collapsed": false}}, {"source": "This shows that the normal interaction in the data set is 0.195 (from sampling and from the entire data set). The duration is about a second slower when operating on the entire data set.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}