{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "# Using map transformation\nnums = sc.parallelize([1, 2, 3, 4])\nsquared = nums.map(lambda x: x * x).collect()\nfor num in squared:\n    print(num)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1499169944872_0009</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn0-kbtu.lzixs4haezju5jpxr1e0wdmnla.ax.internal.cloudapp.net:8088/proxy/application_1499169944872_0009/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.5:30060/node/containerlogs/container_1499169944872_0009_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n1\n4\n9\n16"}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "# flatMap() in Python, splitting lines into words\nlines = sc.parallelize([\"hello world\", \"hi\"])\nwords = lines.flatMap(lambda line: line.split(\" \"))\nwords.first() # returns \"hello\"", "outputs": [{"output_type": "stream", "name": "stdout", "text": "'hello'"}], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "# Print flatmap() output\nprint(words.take(words.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "['hello', 'world', 'hi']"}], "metadata": {"collapsed": false}}, {"execution_count": 4, "cell_type": "code", "source": "# With map()\nwords = lines.map(lambda line: line.split(\" \"))\nprint(words.take(words.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[['hello', 'world'], ['hi']]"}], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "# Create an RDD of {1, 2, 3, 3}\nrdd = sc.parallelize([1, 2, 3, 3])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 6, "cell_type": "code", "source": "# map()\nmap = rdd.map(lambda x: x + 1)\nprint(map.take(map.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[2, 3, 4, 4]"}], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "# flatMap()\nflatmap = rdd.flatMap(lambda x: range(x,4))\nprint(flatmap.take(flatmap.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2, 3, 2, 3, 3, 3]"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "# filter()\nfilter = rdd.filter(lambda x: x != 1)\nprint(filter.take(filter.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[2, 3, 3]"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "# distinct()\ndistinct = rdd.distinct()\nprint(distinct.collect())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2, 3]"}], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "# sample()\nsample = rdd.sample(False, 0.5)\nprint(sample.collect())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2]"}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "# Two-RDD transformations on RDDs containing {1, 2, 3} and {3, 4, 5}\nrdd1 = sc.parallelize([1, 2, 3])\nrdd2 = sc.parallelize([3, 4, 5])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 12, "cell_type": "code", "source": "# union()\nunion = rdd1.union(rdd2)\nprint(union.collect())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2, 3, 3, 4, 5]"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "# subtract()\nsubtract = rdd1.subtract(rdd2)\nprint(subtract.collect())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2]"}], "metadata": {"collapsed": false}}, {"execution_count": 14, "cell_type": "code", "source": "# cartesian()\ncartesian = rdd1.cartesian(rdd2)\nprint(cartesian.collect())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 3), (3, 4), (3, 5)]"}], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "# collect()\ncollect = rdd.collect()\nprint(rdd.collect())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2, 3, 3]"}], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": "# count()\ncount = rdd.count()\nprint(count)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "4"}], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "# take()\ntake = rdd.take(2)\nprint(take)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[1, 2]"}], "metadata": {"collapsed": false}}, {"execution_count": 18, "cell_type": "code", "source": "# top()\ntop = rdd.top(2)\nprint(top)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[3, 3]"}], "metadata": {"collapsed": false}}, {"execution_count": 19, "cell_type": "code", "source": "# Take Sample\ntakeSample = rdd.takeSample(False, 1)\nprint(takeSample)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[3]"}], "metadata": {"collapsed": false}}, {"execution_count": 20, "cell_type": "code", "source": "# reduce()\nfrom operator import add\nreduce = rdd.reduce(add)\nprint(reduce)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "9"}], "metadata": {"collapsed": false}}, {"execution_count": 21, "cell_type": "code", "source": "# fold()\nfrom operator import add\nfold = rdd.fold(0, add)\nprint(fold)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "9"}], "metadata": {"collapsed": false}}, {"execution_count": 22, "cell_type": "code", "source": "# aggregate()\nseqOp = (lambda x, y: (x[0] + y, x[1] + 1))\ncombOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\naggregate = rdd.aggregate((0, 0), seqOp, combOp)\nprint(aggregate)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "(9, 4)"}], "metadata": {"collapsed": false}}, {"execution_count": 23, "cell_type": "code", "source": "# foreach()\ndef f(x): print(x)\nrdd.foreach(f)", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}